# 线性回归

$$
单层神经网络\left \{
\begin{matrix}
线性回归\\
softmax回归
\end{matrix}
\right.
$$

回归问题输出连续值，分类问题输出离散值

## 线性回归的基本要素

### 模型

建立基于输入来计算输出的表达式，由输入与参数计算出输出。

权重（weight）：各个输入的系数

偏差（bias）：一个常数

参数（parameter）：权重与偏差

### 模型训练

通过数据寻找特定的模型参数值，使模型在数据上的误差尽可能小。

### 训练数据

数据集（training data set）：一系列真实数据

样本（sample）：一个真实数据

特征（feature）：输入

标签（label）：输出

### 损失函数

衡量预测值与真实值之间的误差

损失函数（loss function）；衡量误差的函数

我们希望找出参数使得平均损失最小

### 优化算法

解析解（analytical solution）：可以公式化求解误差最小问题

数值解（numerical solution）：只能通过优化算法有限迭代模型参数来尽可能降低误差

#### 小批量随机梯度下降（mini-batch stochastic gradient descent）

先选取一组初始值，之后持续迭代

每次迭代，选择一个固定数目的样本组成的小批量（mini-batch），然后求小批量中损失函数的梯度，之后通过这个梯度修正参数。

公式表达为
$$
P'=P- \frac{\eta}{B}\sum_{j \in B} \nabla Loss(P)
$$
$\eta,B$是认为设定的，叫超参数

超参数（hyperparameter）：人为设定的参数

### 模型预测

用模型去解决数据集外的问题



